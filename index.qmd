---
pagetitle: "Data, Health & Biology"
subtitle: "It's not the size of your data, it's how you use it"
author: "Michael Lydeamore"
email: "michael.lydeamore@monash.edu"
department: "Department of Econometrics and Business Statistics"
unit-url: "https://slides.michaellydeamore.com/2024-adsc-lunchbox"
format: 
  revealjs:
    logo: images/monash-stacked-blue-rgb-transparent.png
    slide-number: true
    multiplex: false
    theme: assets/monash.scss
    show-slide-number: all
    show-notes: false
    controls: true
    width: 1280
    height: 750
    css: [assets/tachyons-addon.css, assets/custom.css, assets/lecture-01.css]
    include-after-body: "assets/after-body.html"
    chalkboard:
      boardmarker-width: 5
      buttons: true
---


```{r, include = FALSE}
current_file <- knitr::current_input()
basename <- gsub(".[Rq]md$", "", current_file)

knitr::opts_chunk$set(
  fig.path = sprintf("images/%s/", basename),
  fig.align = "center",
  out.width = "100%",
  fig.retina = 3,
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  cache = FALSE,
  cache.path = "cache/"
)

library(dplyr)
library(ggplot2)
library(tidyr)
library(deSolve)
library(patchwork)
library(readr)

source("nldr_code.R")
source("quollr_code.R")
```

## <br>[Data, Health & Biology]{.monash-blue .title} {#etc5513-title background-image="images/bg-01.png"}

### `r rmarkdown::metadata$subtitle`

`r rmarkdown::metadata$author`

`r rmarkdown::metadata$department`

::: tl
<br>

<ul class="fa-ul">

<li>

[<i class="fas fa-envelope"></i>]{.fa-li}`r rmarkdown::metadata$email`

</li>

<li>

[<i class="fa-solid fa-globe"></i>]{.fa-li}<a href="`r rmarkdown::metadata[["unit-url"]]`">`r rmarkdown::metadata[["unit-url"]]`</a>

</li>

</ul>

<br>
:::

## My Roadmap {.smaller}

* Bachelor of Mathematical Sciences at the University of Adelaide (completed 2012)
* Masters of Philosophy at the University of Adelaide (completed 2015)
* PhD at the University of Melbourne (completed 2019)
* Joined Monash University in mid-2019
    * Including honorary position at the SaferCare Victoria, Department of Health & Human Services
* Recruited into the COVID-19 response in late February/early March
* Appointed Manager of Analytics in September
* Rejoined Monash in 2021, including the Doherty COVID-19 Modelling Consortium
* Joined EBS in September 2021

# Burden of Healthcare Associated Infections in Australia

Joint work with Brett Mitchell, Tracey Bucknall, Allen Cheng, Phil Russo & Andrew Stewardson

## Healthcare asociated infections {.smaller}

Healthcare associated infections (HAIs) are associated with increased morbidity and mortality.

Five of the most common HAIs are:

* Clostridiodes difficile --- causes severe damage to the colon, can be fatal
* Bloodstream infection (sepsis) --- estimated mortality rate of 15-30%
* Urinary track infection --- low mortality but associated with multi-drug resistance and significantly longer stays
* Healthcare acquired pneumonia --- mortality rate of 40-70%, increasing dramatically with age
* Surgical site infection --- significantly increases length of stay

::: {.fragment}
But, HAIs are not notifiable => We have no robust way to track whether their prevalence is increasing or decreasing.
:::

## Overseas monitoring

HAIs are actively monitored across Europe through the ECDC.

In 2016 (based on 2012 data), 2,609,911 new HAIs are estimated to have occurred.

::: {.fragment}
The data for this was a _point prevalence survey_, on an enormous scale:

* 273,753 patients
* 1,149 hospitals
:::

## Point prevalence survey

A point prevalence survey counts the number of people with a condition on a given day.

We ran a PPS in Australia in 2019, consisting of:

* Adults in [19]{.fragment fragment-index=5} [large]{.fragment fragment-index=2} [acute care]{.fragment fragment-index=4} [public]{.fragment fragment-index=3} hospitals

All acute cards wards were included. Non-acute, paediatric, NICU, rehab, and ED were excluded.

::: {.fragment}
The hospitals sampled make up approximately 60% of all overnight separations in Australia.
:::

## Point prevalence survey

* 2767 patients sampled between 6 Aug and 29 Nov 2018
* Median age: 67 (range 18-104)
* 52.9% male, 46.6% female, 0.5% unknown/other
* 85.7% patients in major city hospitals

# Methodology time

We have to go from point prevalence to annual incidence...

## Estimation methodology

#### Step 1: Estimation of hospital prevalence

Hospital Prevalence ($P$) is estimated as:

$$P = r \times \text{Beta}(n_\text{obs}, N - n_\text{obs}+1) + (1-r) \times \text{Beta}(n_\text{obs}+1, N-n_\text{obs}),$$

where $n_\text{obs}$ is the number of patients observed with a HAI and $N$ is the total number of patients in the PPS.

This is a standard extrapolation from a binomial sample with a lot of zeros.

## Estimation methodology

#### Step 2: Estimation of hospital incidence

Hospital incidence ($I$) calculated as:

$$I = P \frac{LA}{LOI},$$

where:

* $P$ is the hospital prevalence from Step 1
* $LA$ is the mean length of stay and
* $LOI$ is the length of infection

::: {.fragment}
ðŸŽ‰ðŸŽ‰ Australia actually captures $LA$ through the AIHW ðŸŽ‰ðŸŽ‰
:::

## Estimation methodology

#### Step 2a: Length of infection

$LOI$ is not available, but instead we have $LOI_{pps}$ --- the length of infection until the date of survey. We can calculate

$$P(LOI_{pps} = 1),$$

which is just the probability that a patient is in the first day of their HAI. Then,

$$E[LOI] = 1/P(LOI_{pps} = 1).$$

For a small sample size, this is heavily biased, so we take a mixture of this estimator and $E[LOI_{pps}]$.

## Estimation methodology

#### Step 3: Estimation of population incidence

Calculate population incidence simply as

$$I_\text{pop} = I \times N_\text{discharges}.$$

::: {.fragment}
ðŸŽ‰ðŸŽ‰ We capture this too! $N_\text{discharges} = 3,713,513,$ 60% of the total admissions in a given year. 
:::

::: {.fragment}
In the ECDC PPS, this quantity is **not** captured. They estimate using patient-days and the number of patients.
:::

## Estimation methodology

#### Step 4: Stratification by age and sex

Use a multinomial likelihood function with a Dirichlet prior, with weights taken from the number of cases in each age/sex category.

::: {.fragment}
A psuedocount is added to each strata ($0.001 \sum{\text{weights}}$) to ensure the likelihood can be calculated with empty strata.
:::

## Estimation methodology

#### Step 5: Adjustment for life expectancy

Use the "McCabe score", which gives the life expectancy according to secerity of a disease.

Patients are categorised as:

* non-fatal
* fatal (average life expectancy of 3 years)
* [rapidly fatal (average life expectancy of 0.5 years)]{.fragment}

::: {.fragment}
These scores, combined with disease outcome trees, give DALYs and deaths.
:::

## Disease outcome trees

![](images/outcome-tree.pdf){fig-align="center"}

## Key results {.smaller}

::: {.r-stack}

|         | Number of HAIs <br> (95% CI)         | Deaths <br> (95% CI)        | DALYs <br> (95% CI)             |
| ------- | -------------------------------- | ----------------------- | --------------------------- |
| **SSI** | 44,238 <br> (31,176 - 73,797)        | 876 <br> (617 - 1,263)      | 13,197 <br> (9,298 - 19,001)    |
| **UTI** | 42,408 <br> (25,200 - 68,735)        | 729 <br> (259 - 1,772)      | 16,087 <br> (5,939 - 37,218)    |
| **CDI** | 5,125 <br> (2,360 - 10,740)          | 262 <br> (13 - 836)         | 2,757 <br> (241 - 8,655)        |
| **HAP** | 51,499 <br> (31,343 - 82,877)        | 1,904 <br> (462 - 4,430)    | 39,276 <br> (17,608 - 77,915)   |
| **BSI** | 23,979 <br> (15,658 - 36,245)        | 3,512 <br> (1,874 - 6,075)  | 46,773 <br> (26,205 - 79,104)   |
| **All** | **170,574** <br> (135,779 - 213,898) | 7,583 <br> (4,941 - 11,135) | 122,376 <br> (85,136 - 172,784) |

::: {.fragment style="background-color: white; border: solid thick red; padding: 10px;"}
That's 1 in 20 _admissions_ resulting in an avoidable infection!
:::
:::

## Key results

::: {.columns}
::: {.column width='50%'}
![](images/Figure1-cases_per_100k.png){fig-align="center"}

:::
::: {.column width='50%'}
![](images/Figure4-dalys_per_100k.png){fig-align="center"}

:::
:::

## Key results

![](images/Figure2-cases_stratified_per_100k.png){fig-align="center"}

## Key results

![](images/Figure3-deaths_per_100k.png){fig-align="center"}

## Novelty

* First estimate of HAI burden in Australia using (relatively) robust survey data in an established framework
* Based on first point prevalence survey since 1984

* There is no routine surveillance of HAIs in Australia
* Point prevalence surveys remain the only way to understand the burden of these conditions

## Summary

* 498 DALYs per 100,000 is a large amount
    * Motor vehicles: 180 DALYs
    * Infectious diseases: 370 DALYs
    * Respiratory diseases: 1380 DALYs

::: {.fragment}
This work has informed guidance on HAI surveillance in Australia, including new funding schemes to better understand these conditions.
:::

::: {.fragment}
And all this based on just 2767 patients from 19 hospitals...
:::

# HAIs are largely preventable.

They represent great opportunity for improvement, and we have a long way to go to prevent them entirely.

# Visualising how non-linear dimension reduction warps your data

**J. Lakshika**, D. Cook, P. Harrison, T. Talagala, M. Lydeamore

## High dimensional data

The world collects a lot of data. Much of this data is very wide.

This "high-dimensional" data is very challenging to visualise, as we can only see in two dimensions.

::: {.fragment}
One key application area is single-cell RNA data. The main task is to identify groups of cells with similar expression profiles

Data is collected on the amount of a gene expressed by a cell. Similar types of cells should express similar types of certain "marker" genes.
:::

::: {.fragment .center}
#### But how do we check?
:::

## Tours

::: {.columns}
::: {.column width='50%'}
```{r}
#| echo: false

data <- readRDS("data/s_curve.rds")
langevitour::langevitour(data[, 1:7])
```
:::
::: {.column width='50%'}

#### What is a tour?

* Interactive and dynamic graphics to visualise high-dimensional data

#### Why is the tour technique involved?

* Tour shows a sequence of linear projections as a movie
* It involves mentally assembling multiple low-dimensional views to comprehend the structure in higher dimensions

:::
:::


## Dimension reduction 
Dimension reduction is a common way to reduce a high dimensional dataset into a lower number of dimensions.

* Linear techniques (like PCA) are classical techniques that use a linear mapping to reduce dimension
* Recent years has seen non-linear mappings that can maximise variance in a 2D view
* These mappings aim to preserve pairwise distances from high dimensions into lower dimensions

::: {.fragment}
* Common tools include: uMAP, tSNE, PACMAP and more recently, PHATE.
:::

::: {.fragment}
As with anything designed to maximise variance, it is important to check these techniques aren't inventing structures.
:::

## Dimension reduction
Formally speaking, the problem can be specified as:

Consider the High-D data a rectangular matrix $X_{n\times p}$, with $n$ observations and $p$ dimensions. 

We aim to discover a projection $Y_{n \times d}$, i.e. an $n \times d$ matrix with $d \ll p$.

## An example

Five different NLDRs give similar but definitely different curves:

```{r}
tsne_plot <- readRDS("data/s_curve_tsne_27.rds") |>
    plot_tSNE_2D() + # ggtitle("(a)") +
    theme_linedraw() +
    theme(
        plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()
    ) +
    annotate(geom = "text", label = "a", x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

umap_plot <- readRDS("data/s_curve_umap.rds") |>
    plot_UMAP_2D() + # ggtitle("(b)") +
    theme_linedraw() +
    theme(
        plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()
    ) +
    annotate(geom = "text", label = "b", x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

phate_plot <- readRDS("data/s_curve_phate.rds") |>
    plot_PHATE_2D() + # ggtitle("(c)") +
    theme_linedraw() +
    theme(
        plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()
    ) +
    annotate(geom = "text", label = "c", x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

trimap_plot <- readRDS("data/s_curve_trimap.rds") |>
    plot_TriMAP_2D() + # ggtitle("(d)") +
    theme_linedraw() +
    theme(
        plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()
    ) +
    annotate(geom = "text", label = "d", x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)

pacmap_plot <- readRDS("data/s_curve_pacmap.rds") |>
    plot_PaCMAP_2D() + # ggtitle("(e)") +
    theme_linedraw() +
    theme(
        plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()
    ) +
    annotate(geom = "text", label = "e", x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)

# tsne_plot + umap_plot + phate_plot + trimap_plot + pacmap_plot + plot_layout(ncol = 5)
```

```{r}
(tsne_plot + umap_plot + phate_plot) / (trimap_plot + pacmap_plot)
```

## Even the same NLDR looks different

```{r}
#| warning: false
#| echo: false

UMAP_data_7 <- read_rds(file = "data/s_curve_umap_7.rds")

#(n-neighbors: 50)
plot_list1_umap <- plot_UMAP_2D(UMAP_data_7) + #ggtitle("(b)") +
  geom_point(alpha=0.5, size = 0.5, colour = "#8dd3c7", fill = "#8dd3c7") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r}
#| warning: false
#| echo: false

UMAP_data_15 <- read_rds(file = "data/s_curve_umap_15.rds")

#(n-neighbors: 50)
plot_list2_umap <- plot_UMAP_2D(UMAP_data_15) + #ggtitle("(b)") + 
  geom_point(alpha=0.5, size = 0.5, colour = "#a65628", fill = "#a65628") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r}
#| warning: false
#| echo: false

UMAP_data_32 <- read_rds(file = "data/s_curve_umap_32.rds")

#(n-neighbors: 50)
plot_list3_umap <- plot_UMAP_2D(UMAP_data_32) + #ggtitle("(b)") +
  geom_point(alpha=0.5, size = 0.5, color = "#f781bf", fill = "#f781bf") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'c', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r}
#| warning: false
#| echo: false

UMAP_data <- read_rds(file = "data/s_curve_umap.rds")

#(n-neighbors: 50)
plot_list4_umap <- plot_UMAP_2D(UMAP_data) + #ggtitle("(b)") +
  geom_point(alpha=0.5, size = 0.5, colour = "#999999", fill = "#999999") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'd', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r}
(plot_list1_umap + plot_list2_umap) / (plot_list3_umap + plot_list4_umap)
```

## A method to analyse goodness-of-fit

We have developed a method to project the 2D dimension reduction back into higher dimensions where we can visualise discrepancies.

The algorithm has four steps:

::: {.incremental}

1. Parition DR data into hexagonal bins
2. Triangulate centroids of these bins to form a 2D manifold
3. Map the 2D bins to High-D using the points contained within each bin
4. Measure "model error" and visualise in High-D

:::

## Step 1: Partitioning DR data into hexagonal bins
::: {.columns}
::: {.column width='50%'}
![](images/hexagonate_example.jpg){fig-align="center" height="575px"}
:::
::: {.column width='50%'}
```{r}
#| fig-height: 10
df_bin_centroids_all <- readRDS("data/df_bin_centroids_all.rds")
readRDS("data/hex_full_count_df.rds") |>
ggplot(aes(x = x, y = y)) +
    geom_polygon(color = "black", aes(group = polygon_id), fill = "#FFFFFF") +
    geom_point(data = df_bin_centroids_all, aes(x = x, y = y), color = "#33A02C", size = 4) +
    theme_light() +
    coord_fixed() + 
    theme(
        legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank() # change legend key width
    )
```
:::
:::

::: {.aside}
I believe this should be called "hexagonate..."
:::


## Step 2: Triangulate centroids of these bins
::: {.columns}
::: {.column width='50%'}
Use Delauney triangulation to create a triangular mesh that is representative of the 2D data.

::: {.note .smaller .fragment}
Beause our hexagons are regular the resulting triangles will be _mostly_ equilateral (which is nice)
:::
:::
::: {.column width='50%'}
```{r}
#| fig-height: 10
tr_from_to_df_all <- readRDS("data/tr_from_to_df_all.rds")
trimesh_all <- ggplot(df_bin_centroids_all, aes(x = x, y = y)) +
    geom_segment(data = tr_from_to_df_all, aes(x = x_from, y = y_from, xend = x_to, yend = y_to)) +
    geom_point(size = 4, colour = "#33A02C") +
    coord_equal()
trimesh_all <- trimesh_all +
  #ggtitle("(a)") +
  xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  theme_light() +
    theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
          axis.title.x = element_blank(), axis.title.y = element_blank(),
          axis.text.x = element_blank(), axis.ticks.x = element_blank(),
          axis.text.y = element_blank(), axis.ticks.y = element_blank(),
          panel.grid.major = element_blank(), panel.grid.minor = element_blank()
    )

trimesh_all

```

:::
:::

## Step 2a: Removing "long" edges

Sometimes triangulation will give edges between two very distant nodes. This is not an accurate representation of the 2D surface, so we trim them off

![](images/long-edges.jpg){fig-align="center"}

## Step 3: Map from 2D to High-D

::: {.fragment}
Define the function $f: \mathbb{R}^p \rightarrow \mathbb{R}^2$ which maps the high-D point to it's NLDR equivalent.

:::

::: {.fragment}

Let the set of all points in a single hexagon $i$ be denoted by $\mathbb{H}_i$, with centroid $\mathcal{h}_i$. 
:::
::: {.fragment}

Then, let $g: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ be a function that maps each point in 2D space to it's closest centroid.

It follows that $f(g(x))$ maps the high-D point to the centroid in 2D.
:::


## Step 3: Map from 2D to High-D

Define the high-dimension mean of all the points in $\mathbb{H}_i$ by $\hat{h}_i$. That is,

$$\hat{h}^{(p)} = \frac{1}{|\mathbb{H}_i|}\sum_{x \in \mathbb{H}_i} \sum_{l = 1}^p x_{\cdot,l}$$

::: {.fragment}
Finally, we choose a function $v: \mathbb{R}^2 \rightarrow \mathbb{R}^p$ such that $$v(\mathcal{h}_i) = \hat{h}^{(p)}.$$

:::


::: {.fragment}
[That is, the function $v$ maps the 2D centroid to the high-D mean of the points in the hexagon.]{.monash-blue}
:::

## Step 3: Map from 2D to High-D

So, $(f \circ g)(x)$ gives the 2D centroid associated with $x$, and $v(h_i)$ gives the high-D centroid associated with 2D point $h_i$.

Thus, $v(f \circ g)(x)$ gives the high-D centroid associated with the 2D embedding of the point $x$.

::: {.fragment}
We use this process to define a model of the 2D embedding in high dimensions, allowing us to visualise and compute error.
:::

## Step 4: Visualise model fit in High-D

```{r}
df_exe <- readRDS("data/df_exe.rds")
distance_df_small_edges <- readRDS("data/distance_df_small_edges.rds")
langevitour::langevitour(df_exe[1:(length(df_exe)-1)], lineFrom = distance_df_small_edges$from, lineTo = distance_df_small_edges$to, group = df_exe$type, levelColors = c("#807dba" , "#000000"))
```

## Real-world example: PBMC dataset


```{r}
#| out-width: 100%
#| fig-pos: h

UMAP_pbmc <- read_rds("data/pbmc_umap.rds")


class_avg <- UMAP_pbmc |>
  group_by(cell_label) |>
  summarise(
    UMAP1 = median(UMAP1),
    UMAP2 = median(UMAP2)
  ) |>
  mutate(cell_label = as.numeric(cell_label)) |>
  arrange(cell_label)

class_avg$cell_label <- as.factor(class_avg$cell_label)

levels(class_avg$cell_label) <- c("Memory \nCD4 T", "Naive CD4 T", "CD14+ Mono",  "B", "CD8 T", "FCGR3A+ \n Mono", "NK", "M-MDSC\n-like", "CD27-CD+ \n Memory T", "DC")


plot_list2_pbmc <- UMAP_pbmc |>
    ggplot(aes(x = UMAP1,
               y = UMAP2, color = cell_label))+
    geom_point(alpha=0.5) +
    coord_equal() +
    theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold")) + #ggtitle("(a)") +
  theme_linedraw() +
    theme(legend.position = "none", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
              axis.title.x = element_blank(), axis.title.y = element_blank(),
              axis.text.x = element_blank(), axis.ticks.x = element_blank(),
              axis.text.y = element_blank(), axis.ticks.y = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
         legend.key.height = unit(0.25, 'cm'),
         legend.key.width = unit(0.25, 'cm')) +
  scale_color_manual(values=c("#b15928", "#1f78b4", "#cab2d6", "#ccebc5", "#fb9a99", "#e31a1c", "#6a3d9a", "#ff7f00", "#ffed6f", "#fdbf6f", "#ffff99", "#a6cee3", "#8dd3c7", "#ffffb3", "#bebada", "#fb8072", "#80b1d3", "#fdb462", "#b3de69", "#fccde5", "#d9d9d9", "#b2df8a", "#bc80bd", "#33a02c", "#ccebc5", "#ffed6f", "#000000", "#bdbdbd")) +
  geom_text(aes(x=UMAP1,y = UMAP2,label = cell_label), data = class_avg,inherit.aes = F, color = "black",fontface = "bold",size = 2) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)



num_bins_pbmc <- 15

shape_value_pbmc <- calculate_effective_shape_value(.data = UMAP_pbmc,
                                                      x = UMAP1, y = UMAP2) ## 0.8772751

## To extract bin centroids
hexbin_data_object_pbmc <- extract_hexbin_centroids(nldr_df = UMAP_pbmc,
                                                      num_bins = num_bins_pbmc,
                                                      shape_val = shape_value_pbmc, x = UMAP1, y = UMAP2)

df_bin_centroids_pbmc <- hexbin_data_object_pbmc$hexdf_data

#num_non_empty_bins_pbmc <- df_bin_centroids_pbmc$hexID |> length() #83



## Triangulate bin centroids
tr1_object_pbmc <- triangulate_bin_centroids(df_bin_centroids_pbmc, x, y)
tr_from_to_df_pbmc <- generate_edge_info(triangular_object = tr1_object_pbmc)

## Compute 2D distances
distance_pbmc <- cal_2d_dist(.data = tr_from_to_df_pbmc)

## To find the benchmark value
benchmark_pbmc <- find_benchmark_value(.data = distance_pbmc, distance_col = distance)
benchmark_pbmc <- 2.5
  

trimesh_removed_pbmc_umap <- remove_long_edges(.data = distance_pbmc, benchmark_value = benchmark_pbmc,
                                                 triangular_object = tr1_object_pbmc, distance_col = distance)

trimesh_removed_pbmc_umap <- trimesh_removed_pbmc_umap +
  geom_point(size = 1, colour = "#33a02c") +
  #ggtitle("(b)") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

training_data_pbmc <- read_rds("data/pbmc_pca_50.rds")
training_data_pbmc <- training_data_pbmc[, 1:15] |>
  mutate(ID = 1:NROW(training_data_pbmc))

UMAP_pbmc_with_hb_id <- UMAP_pbmc |>
  dplyr::mutate(hb_id = hexbin_data_object_pbmc$hb_data@cID)

plot_list2_pbmc_error <- readRDS("data/plot_list2_pbmc_error.rds")

plot_list2_pbmc + trimesh_removed_pbmc_umap + plot_list2_pbmc_error +
plot_layout(guides='collect', ncol=3) &
  theme(legend.position='bottom')
```

## Summary

::: {.columns}
::: {.column width='50%'}
* Dimension reduction is hard
* Maximising variance can create or elongate structures that may not be present in the data
* Visualising in high dimensions using a tour is a way to assess model fit
* This algorithm helps create an easier visualisation for end users

:::
::: {.column width='50%'}
::: {.fragment}

![Jayani Lakshika, PhD Candidate](images/jayani.jpg){fig-align="center" height="350px" style="text-align: center;"}
:::
:::
:::

## Data science and impact 

#### Don't let a small amount of data limit your reach

::: {.incremental}
* Data is expensive, we all want more all the time...
* But a "handful" of observations can lead to real change
* At the same time, more data does not always mean more good

:::

::: {.fragment .incremental}
* You can't model your way out of bad data
* But you can model good data badly
:::

::: {.fragment}
#### Impactful projects rely on good people, good problems and good techniques. {.center}

:::

